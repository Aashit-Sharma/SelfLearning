{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of iterations was 13\n",
      "The total error was 0.0034822214269\n",
      "The final change in error was 0.00577180168398\n",
      "The final parameters were [ -17.84374926  -14.0620823   163.06478261]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f0403a6bd10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import scipy.integrate as sciInt\n",
    "import scipy.optimize as sciOpt\n",
    "\n",
    "seed = 123456789\n",
    "np.random.seed(seed)\n",
    "N = 100 #number of data points, SEE WHAT HAPPENS AS YOU INCREASE THIS TO SAY 200\n",
    "D = 2   #dimension of input vector\n",
    "t = np.zeros(N) #training set classifications\n",
    "X = np.zeros((N,D)) #training data in input space\n",
    "sigma = .25\n",
    "mu0 = 0.0\n",
    "mu1 = 1.0\n",
    "\n",
    "#func for generating 2D class scatter plot\n",
    "def createScatter(X, t, ax):\n",
    "    C1x = []  \n",
    "    C1y = []\n",
    "    C2x = []\n",
    "    C2y = []\n",
    "    for i in range(len(t)):\n",
    "        if t[i] > 0: \n",
    "            C1x.append(X[i,0])\n",
    "            C1y.append(X[i,1])\n",
    "        else: \n",
    "            C2x.append(X[i,0])\n",
    "            C2y.append(X[i,1])\n",
    "    ax.scatter(C1x,C1y)\n",
    "    ax.scatter(C2x,C2y, color='r')\n",
    "    \n",
    "#Generate test data. (NOTE THIS IS NOT BASED ON A GENERATIVE APPROACH. I AM PICKING SOMETHING THAT I KNOW (OK, THINK) WILL WORK. IN PRACTICE THIS DATA WOULD BE OBTAINED VIA OBSERVATION)\n",
    "#Pick a value from a uniform distribution [0,1). If it is less than 0.5, assign class 1 and pick x1,x2 from a ND(mu0,sigma) otherwise assign class 2 and pick x1,x2 from ND(mu1,sigma)\n",
    "for i in range(N):\n",
    "    #choose class to sample for\n",
    "    fac = 1\n",
    "    if np.random.rand() <= 0.5:\n",
    "        thismu = mu0\n",
    "        t[i] = 1\n",
    "    else: \n",
    "        thismu = mu1\n",
    "        t[i] = 0\n",
    "        if np.random.rand() < 0.5: fac = -1\n",
    "        \n",
    "    X[i,0] = fac * np.random.normal(thismu, sigma)\n",
    "    X[i,1] = fac * np.random.normal(thismu, sigma)\n",
    "    \n",
    "\n",
    "f, axarr = plt.subplots(1,3)\n",
    "f.subplots_adjust(right=2.5)\n",
    "f.text(0.75,0.975,'Fixed Input Transformation Yields Linear Class Boundary',horizontalalignment='center',verticalalignment='top')\n",
    "\n",
    "ax1 = axarr[0]\n",
    "ax1.set_xlabel('x1')\n",
    "ax1.set_ylabel('x2')\n",
    "createScatter(X,t,ax1)\n",
    "\n",
    "#The training data does not have a linear boundary in the original input space. So lets apply a tranformation, phi to try to make it linearly seperable\n",
    "#NOTE: This transformation is not the only one that works. For example try switching the values of MU1 and MU2. The result will be a different mapping\n",
    "#that is still linearly seperable\n",
    "def phi(x,mu,sigma):\n",
    "    detSigma = np.linalg.det(sigma)\n",
    "    fac = math.pow(2*math.pi, len(mu)/2.0) * math.sqrt(detSigma)\n",
    "    arg = -0.5 * np.dot((x-mu).T, np.dot(np.linalg.inv(sigma), x-mu) )\n",
    "    return math.exp(arg) / fac\n",
    "    \n",
    "phiX = np.zeros((N,D))\n",
    "MU1 = np.ones(D)*mu0\n",
    "MU2 = np.ones(D)*mu1\n",
    "SIGMA = np.diag(np.ones(D))*sigma\n",
    "for i in range(N):\n",
    "    phiX[i,0] = phi(x=X[i,:], mu=MU2, sigma=SIGMA)\n",
    "    phiX[i,1] = phi(x=X[i,:], mu=MU1, sigma=SIGMA)\n",
    "    \n",
    "ax2 = axarr[1]\n",
    "ax2.set_xlabel('phi1(x)')\n",
    "ax2.set_ylabel('phi2(x)')\n",
    "createScatter(phiX, t, ax2)\n",
    "\n",
    "#Now lets apply machine learning to determine the boundary. We will assume M = 3, i.e. that there are 3 free parameters that is w = [w0, w1, w2]^T and phi_n = [1, phiX[0], phiX[1]]\n",
    "M = 3\n",
    "Phi = np.ones((N,M))\n",
    "Phi[:,1] = phiX[:,0]\n",
    "Phi[:,2] = phiX[:,1]\n",
    "w = np.zeros(M)\n",
    "R = np.zeros((N,N))\n",
    "y = np.zeros(N)\n",
    "\n",
    "def sigmoid(a):\n",
    "   return 1.0 / (1.0 + math.exp(-a))\n",
    "\n",
    "def totalErr(y,t):\n",
    "    e = 0.0\n",
    "    for i in range(len(y)):\n",
    "        if t[i] > 0:\n",
    "            e += math.log(y[i])\n",
    "        else:\n",
    "            e += math.log(1.0 - y[i])\n",
    "    return -e\n",
    "\n",
    "#start Newton-Raphson. As a stopping criteria we will use a tolerance on the change in the error function and a max number of iterations\n",
    "max_its = 100\n",
    "tol = 1e-2\n",
    "w0 = [w[0]] \n",
    "w1 = [w[1]]\n",
    "w2 = [w[2]]\n",
    "err = []\n",
    "error_delta = 1 + tol\n",
    "current_error = 0\n",
    "idx = 0\n",
    "while math.fabs(error_delta)>tol and idx < max_its:\n",
    "    #update y & R\n",
    "    for i in range(N): \n",
    "        zipped = zip(w, Phi[i,:])\n",
    "        y[i] = sigmoid(reduce(lambda accum, Z: accum + Z[0]*Z[1], zipped, 0))\n",
    "        R[i,i] = y[i] - y[i]*y[i]\n",
    "    #update w\n",
    "    z = np.dot(Phi,w) - np.dot(np.linalg.pinv(R),y-t)\n",
    "    temp = np.linalg.pinv(np.dot(np.dot(Phi.T,R),Phi))\n",
    "    temp2 = np.dot(np.dot(temp, Phi.T),R)\n",
    "    w = np.dot(temp2, z)\n",
    "    w0.append(w[0])\n",
    "    w1.append(w[1])\n",
    "    w2.append(w[2])\n",
    "    idx += 1\n",
    "    temp = totalErr(y,t)\n",
    "    error_delta = current_error - temp\n",
    "    current_error = temp\n",
    "    err.append(error_delta)\n",
    "print 'The total number of iterations was {0}'.format(idx)\n",
    "print 'The total error was {0}'.format(current_error)\n",
    "print 'The final change in error was {0}'.format(error_delta)\n",
    "print 'The final parameters were {0}'.format(w)    \n",
    "    \n",
    "#our decision boundary is now formed by the line where sigma(a) = 0.5, i.e. where a = 0, which for this example is where phi2 = -(w1/w2)phi1, i.e. where w * phi = .5\n",
    "bdryx = (0,1)\n",
    "bdryy = (-(w[0]+w[1]*bdryx[0])/w[2], -(w[0]+w[1]*bdryx[1])/w[2])\n",
    "ax2.plot(bdryx, bdryy)\n",
    "\n",
    "ax3 = axarr[2]\n",
    "ax3.plot(w0, color = 'blue')\n",
    "ax3.plot(w1, color = 'red')\n",
    "ax3.plot(w2, color = 'green')\n",
    "ax3.plot(err, color = 'black')\n",
    "ax3.legend((\"w0\",\"w1\",\"w2\", \"error delta\"), loc='upper left')\n",
    "ax3.set_xlabel('Newton-Raphson Iteration')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
